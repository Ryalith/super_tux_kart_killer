{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b82c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stk_actor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e0bd3",
   "metadata": {},
   "source": [
    "# PPO Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0a9766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n"
     ]
    }
   ],
   "source": [
    "env = stk_actor.env.make_discrete_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b184fe2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoxList(boxes=[CategoricalBox(n=5), CategoricalBox(n=2), CategoricalBox(n=2), CategoricalBox(n=2), CategoricalBox(n=2), CategoricalBox(n=2), CategoricalBox(n=7)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.specs[\"input_spec\"][\"full_action_spec\"][\"action\"].space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407ede5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_algorithm = stk_actor.algorithms.PPOAlgo(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d0e134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rya/Partage_VM/MS2A/RL/pystk2/stk_actor/agents.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.upper_bounds = torch.tensor(upper_bounds)\n",
      "/home/rya/.venvs/deepdac/lib/python3.11/site-packages/tensordict/nn/probabilistic.py:723: UserWarning: deterministic_sample wasn't found when queried on <class 'stk_actor.agents.MultiCategorical'>. SafeProbabilisticModule is falling back on mode instead. For better code quality and efficiency, make sure to either provide a distribution with a deterministic_sample attribute or to change the InteractionMode to the desired value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_mode=tensor([1., 0., 1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtraining_algorithm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m*\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Partage_VM/MS2A/RL/pystk2/stk_actor/algorithms.py:126\u001b[39m, in \u001b[36mPPOAlgo.train\u001b[39m\u001b[34m(self, total_frames, frames_per_batch, sub_batch_size, device)\u001b[39m\n\u001b[32m    120\u001b[39m optim = torch.optim.Adam(loss_module.parameters(), \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    122\u001b[39m scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n\u001b[32m    123\u001b[39m     optim, total_frames // frames_per_batch, \u001b[32m0.0\u001b[39m\n\u001b[32m    124\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollector\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_val\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_one_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtensordict_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m        \u001b[49m\u001b[43madvantage_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/torchrl/collectors/collectors.py:343\u001b[39m, in \u001b[36mDataCollectorBase.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[TensorDictBase]:\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterator()\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    345\u001b[39m         \u001b[38;5;28mself\u001b[39m.shutdown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/torchrl/collectors/collectors.py:1268\u001b[39m, in \u001b[36mSyncDataCollector.iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m   1267\u001b[39m     torchrl_logger.info(\u001b[33m\"\u001b[39m\u001b[33mCollector: rollout.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1268\u001b[39m tensordict_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1270\u001b[39m     \u001b[38;5;66;03m# if a replay buffer is passed and self.extend_buffer=False, there is no tensordict_out\u001b[39;00m\n\u001b[32m   1271\u001b[39m     \u001b[38;5;66;03m#  frames are updated within the rollout function\u001b[39;00m\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/torchrl/_utils.py:404\u001b[39m, in \u001b[36maccept_remote_rref_invocation.<locals>.unpack_rref_and_invoke_function\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _os_is_windows \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, torch._C._distributed_rpc.PyRRef):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28mself\u001b[39m.local_value()\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/torchrl/collectors/collectors.py:1534\u001b[39m, in \u001b[36mSyncDataCollector.rollout\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1533\u001b[39m     env_input = \u001b[38;5;28mself\u001b[39m._shuttle\n\u001b[32m-> \u001b[39m\u001b[32m1534\u001b[39m env_output, env_next_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep_and_maybe_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shuttle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env_output:\n\u001b[32m   1537\u001b[39m     \u001b[38;5;66;03m# ad-hoc update shuttle\u001b[39;00m\n\u001b[32m   1538\u001b[39m     next_data = env_output.get(\u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/torchrl/envs/common.py:3670\u001b[39m, in \u001b[36mEnvBase.step_and_maybe_reset\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   3668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict.device != \u001b[38;5;28mself\u001b[39m.device:\n\u001b[32m   3669\u001b[39m     tensordict = tensordict.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m3670\u001b[39m tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3671\u001b[39m \u001b[38;5;66;03m# done and truncated are in done_keys\u001b[39;00m\n\u001b[32m   3672\u001b[39m \u001b[38;5;66;03m# We read if any key is done.\u001b[39;00m\n\u001b[32m   3673\u001b[39m tensordict_ = \u001b[38;5;28mself\u001b[39m._step_mdp(tensordict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/torchrl/envs/common.py:2102\u001b[39m, in \u001b[36mEnvBase.step\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   2099\u001b[39m next_preset = tensordict.get(\u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2102\u001b[39m     next_tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2103\u001b[39m     next_tensordict = \u001b[38;5;28mself\u001b[39m._step_proc_data(next_tensordict)\n\u001b[32m   2104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2105\u001b[39m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[32m   2106\u001b[39m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[32m   2107\u001b[39m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/torchrl/envs/gym_like.py:452\u001b[39m, in \u001b[36mGymLikeEnv._step\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m    450\u001b[39m reward = \u001b[32m0\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.wrapper_frame_skip):\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     step_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m     (\n\u001b[32m    454\u001b[39m         obs,\n\u001b[32m    455\u001b[39m         _reward,\n\u001b[32m   (...)\u001b[39m\u001b[32m    459\u001b[39m         info_dict,\n\u001b[32m    460\u001b[39m     ) = \u001b[38;5;28mself\u001b[39m._output_transform(step_result)\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _reward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/pystk2_gymnasium/definitions.py:70\u001b[39m, in \u001b[36mActionObservationWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m     67\u001b[39m ) -> Tuple[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m     68\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[33;03m    :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     action = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28mself\u001b[39m.env.step(action)\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observation(observation), reward, terminated, truncated, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/deepdac/lib/python3.11/site-packages/pystk2_gymnasium/wrappers.py:162\u001b[39m, in \u001b[36mFlattenerWrapper.action\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.action_flattener.only_continuous:\n\u001b[32m    159\u001b[39m     actions = (\n\u001b[32m    160\u001b[39m         action \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.action_flattener.only_discrete \u001b[38;5;28;01melse\u001b[39;00m action[\u001b[33m\"\u001b[39m\u001b[33mdiscrete\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    161\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.action_flattener.discrete_keys) == \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m, (\n\u001b[32m    163\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNot enough discrete values: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mexpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.action_flattener.discrete_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    165\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(action)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    166\u001b[39m     )\n\u001b[32m    167\u001b[39m     discrete_actions = {\n\u001b[32m    168\u001b[39m         key: key_action\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, key_action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.action_flattener.discrete_keys, actions)\n\u001b[32m    170\u001b[39m     }\n\u001b[32m    172\u001b[39m continuous_actions = {}\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "training_algorithm.train(128*100, 128, 32, \"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
